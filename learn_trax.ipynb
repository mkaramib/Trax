{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "learn-trax.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMZxn3LyzlCNZRCEDMAaZUR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkaramib/Trax/blob/main/learn_trax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYXdr-lFA3g3"
      },
      "source": [
        "Trax is a deep learning library implemented by Google brain team. In this page, I will show some experiments with Trax."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0_34FWzBHqe"
      },
      "source": [
        "import os \n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKud0-quCHmI"
      },
      "source": [
        "In this stage we need to install Trax. Following lines of code, will install it for us.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQrhtsaKIeKP"
      },
      "source": [
        "# Install Trax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6I7rUR5CP7c"
      },
      "source": [
        "#@title\n",
        "# Import Trax\n",
        "\n",
        "!pip install -q -U trax\n",
        "import trax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz50-Nm4Im8x"
      },
      "source": [
        "# Pre-trained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JL11zPfsCuua"
      },
      "source": [
        "In this section, I will experiment a machine translation provided by Trax team. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdetqXtzC-Ev",
        "outputId": "a7dafa83-1837-45da-dc7b-1b4486d1d7c8"
      },
      "source": [
        "# Create a Transformer model.\n",
        "# Pre-trained model config in gs://trax-ml/models/translation/ende_wmt32k.gin\n",
        "model = trax.models.Transformer(\n",
        "    input_vocab_size=33300,\n",
        "    d_model=512, d_ff=2048,\n",
        "    n_heads=8, n_encoder_layers=6, n_decoder_layers=6,\n",
        "    max_len=2048, mode='predict')\n",
        "\n",
        "# Initialize using pre-trained weights.\n",
        "model.init_from_file('gs://trax-ml/models/translation/ende_wmt32k.pkl.gz',\n",
        "                     weights_only=True)\n",
        "\n",
        "# Tokenize a sentence.\n",
        "sentence = 'It is nice to learn new things today!'\n",
        "sentence = 'I love to learn Trax.'\n",
        "tokenized = list(trax.data.tokenize(iter([sentence]),  # Operates on streams.\n",
        "                                    vocab_dir='gs://trax-ml/vocabs/',\n",
        "                                    vocab_file='ende_32k.subword'))[0]\n",
        "\n",
        "# Decode from the Transformer.\n",
        "tokenized = tokenized[None, :]  # Add batch dimension.\n",
        "tokenized_translation = trax.supervised.decoding.autoregressive_sample(\n",
        "    model, tokenized, temperature=0.0)  # Higher temperature: more diverse results.\n",
        "\n",
        "# De-tokenize,\n",
        "tokenized_translation = tokenized_translation[0][:-1]  # Remove batch and EOS.\n",
        "translation = trax.data.detokenize(tokenized_translation,\n",
        "                                   vocab_dir='gs://trax-ml/vocabs/',\n",
        "                                   vocab_file='ende_32k.subword')\n",
        "print(translation)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ich liebe Trax zu lernen.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsLnoR2tIX7m"
      },
      "source": [
        "# Trax and Numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aseywL1yDHgy"
      },
      "source": [
        "One of the key feature of Trax is speed which is achieved by using a fast version of numpy using JAX. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKiLKNUODRBi"
      },
      "source": [
        "from trax.fastmath import numpy as fastnp\n",
        "trax.fastmath.use_backend('jax')  # Can be 'jax' or 'tensorflow-numpy'.\n",
        "\n",
        "matrix = fastnp.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "print(f'matrix =\\n{matrix}')\n",
        "vector = fastnp.ones(3)\n",
        "print(f'vector = {vector}')\n",
        "product = fastnp.dot(vector, matrix)\n",
        "print(f'product = {product}')\n",
        "tanh = fastnp.tanh(product)\n",
        "print(f'tanh(product) = {tanh}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}